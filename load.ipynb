{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f0b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\", 5432)\n",
    "}\n",
    "\n",
    "def create_weather_table(cursor):\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS weather_data (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            timestamp TIMESTAMPTZ,\n",
    "            city TEXT,\n",
    "            description TEXT,\n",
    "            temperature REAL,\n",
    "            humidity INTEGER,\n",
    "            pressure INTEGER,\n",
    "            wind_speed REAL\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "def insert_weather_data(cursor, weather):\n",
    "    cursor.execute('''\n",
    "        INSERT INTO weather_data (\n",
    "            timestamp, city, description, temperature,\n",
    "            humidity, pressure, wind_speed\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    ''', (\n",
    "        weather[\"timestamp\"],\n",
    "        weather[\"city\"],\n",
    "        weather[\"description\"],\n",
    "        weather[\"temperature\"],\n",
    "        weather[\"humidity\"],\n",
    "        weather[\"pressure\"],\n",
    "        weather[\"wind_speed\"]\n",
    "    ))\n",
    "\n",
    "def load_to_db(weather):\n",
    "    if not weather:\n",
    "        print(\"[INFO] No weather data to load.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                create_weather_table(cur)\n",
    "                insert_weather_data(cur, weather)\n",
    "        print(\"[INFO] Weather data loaded.\")\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(f\"[ERROR] DB error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4265db2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:34:26.391 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8169</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/3.0/manage/self-host#self-host-a-prefect-server</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:34:26.391 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8169\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/3.0/manage/self-host#self-host-a-prefect-server\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:34:57.952 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'fractal-trogon'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'fractal-trogon'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Weather Data Pipeline'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:34:57.952 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'fractal-trogon'\u001b[0m - Beginning flow run\u001b[35m 'fractal-trogon'\u001b[0m for flow\u001b[1;35m 'Weather Data Pipeline'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:34:57.959 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'fractal-trogon'</span> - Starting weather pipeline\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:34:57.959 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'fractal-trogon'\u001b[0m - Starting weather pipeline\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:02.151 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-3c5' - Fetching data for Nairobi\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:02.151 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-3c5' - Fetching data for Nairobi\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:03.194 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-3c5' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:03.194 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-3c5' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:04.079 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-79a' - Fetching data for London\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:04.079 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-79a' - Fetching data for London\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:04.983 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-79a' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:04.983 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-79a' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:05.854 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-5dc' - Fetching data for New York\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:05.854 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-5dc' - Fetching data for New York\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:06.741 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-5dc' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:06.741 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-5dc' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:07.610 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-c50' - Fetching data for Tokyo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:07.610 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-c50' - Fetching data for Tokyo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:08.467 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_weather_data-c50' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:08.467 | \u001b[36mINFO\u001b[0m    | Task run 'extract_weather_data-c50' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:10.050 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'load_to_db-673' - Database error: column \"feels_like\" of relation \"weather_data\" does not exist\n",
       "LINE 3: ...       timestamp, city, description, temperature, feels_like...\n",
       "                                                             ^\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:10.050 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'load_to_db-673' - Database error: column \"feels_like\" of relation \"weather_data\" does not exist\n",
       "LINE 3: ...       timestamp, city, description, temperature, feels_like...\n",
       "                                                             ^\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:10.345 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_to_db-673' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:10.345 | \u001b[36mINFO\u001b[0m    | Task run 'load_to_db-673' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:10.351 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'fractal-trogon'</span> - Weather pipeline completed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:10.351 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'fractal-trogon'\u001b[0m - Weather pipeline completed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:35:10.418 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'fractal-trogon'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:35:10.418 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'fractal-trogon'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PrefectImportError",
     "evalue": "`prefect.deployments:Deployment` has been removed. Use `flow.serve()`, `flow.deploy()`, or `prefect deploy` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPrefectImportError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 438\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# --- Create deployment (uncomment to deploy) ---\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    436\u001b[39m \u001b[38;5;66;03m#     # For Prefect 2.x deployments, use the CLI or the following:\u001b[39;00m\n\u001b[32m    437\u001b[39m \u001b[38;5;66;03m#     # Import needed only if deploying\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeployments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Deployment\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01morion\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschemas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschedules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntervalSchedule\n\u001b[32m    441\u001b[39m     deployment = Deployment.build_from_flow(\n\u001b[32m    442\u001b[39m         flow=weather_pipeline,\n\u001b[32m    443\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mscheduled-weather-pipeline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    444\u001b[39m         schedule=IntervalSchedule(interval=timedelta(hours=Config.SCHEDULE_INTERVAL_HOURS)),\n\u001b[32m    445\u001b[39m         work_queue_name=\u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\prefect\\deployments\\__init__.py:23\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     21\u001b[39m dynamic_attr = _public_api.get(attr_name)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamic_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattr_migration\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m package, module_name = dynamic_attr\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_module\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\prefect\\_internal\\compatibility\\migration.py:156\u001b[39m, in \u001b[36mgetattr_migration.<locals>.wrapper\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m REMOVED_IN_V3.keys():\n\u001b[32m    155\u001b[39m     error_message = REMOVED_IN_V3[import_path]\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PrefectImportError(\n\u001b[32m    157\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` has been removed. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m     )\n\u001b[32m    160\u001b[39m \u001b[38;5;28mglobals\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = sys.modules[module_name].\u001b[34m__dict__\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m:\n",
      "\u001b[31mPrefectImportError\u001b[39m: `prefect.deployments:Deployment` has been removed. Use `flow.serve()`, `flow.deploy()`, or `prefect deploy` instead."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Dict, List, Any, Optional\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "from prefect import flow, task, get_run_logger\n",
    "from prefect.tasks import task_input_hash\n",
    "import requests\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "from psycopg2 import pool\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Global connection pool\n",
    "DB_POOL = None\n",
    "\n",
    "# --- Configuration ---\n",
    "class Config:\n",
    "    \"\"\"Configuration class to centralize settings\"\"\"\n",
    "    # API settings\n",
    "    OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "    CITIES = os.getenv(\"CITIES\", \"Nairobi,London,New York,Tokyo\").split(\",\")\n",
    "    WEATHER_UNITS = os.getenv(\"WEATHER_UNITS\", \"metric\")\n",
    "    API_TIMEOUT = int(os.getenv(\"API_TIMEOUT\", \"10\"))\n",
    "    \n",
    "    # Database settings  \n",
    "    DB_CONFIG = {\n",
    "        \"host\": os.getenv(\"DB_HOST\", \"localhost\"),\n",
    "        \"dbname\": os.getenv(\"DB_NAME\", \"weather_db\"),\n",
    "        \"user\": os.getenv(\"DB_USER\", \"postgres\"),\n",
    "        \"password\": os.getenv(\"DB_PASSWORD\", \"\"),\n",
    "        \"port\": int(os.getenv(\"DB_PORT\", \"5432\"))\n",
    "    }\n",
    "    \n",
    "    # Email settings\n",
    "    EMAIL_ENABLED = os.getenv(\"EMAIL_ENABLED\", \"false\").lower() == \"true\"\n",
    "    EMAIL_SENDER = os.getenv(\"EMAIL_SENDER\", \"\")\n",
    "    EMAIL_PASSWORD = os.getenv(\"EMAIL_PASSWORD\", \"\")\n",
    "    EMAIL_RECIPIENT = os.getenv(\"EMAIL_RECIPIENT\", \"\")\n",
    "    SMTP_SERVER = os.getenv(\"SMTP_SERVER\", \"smtp.gmail.com\")\n",
    "    SMTP_PORT = int(os.getenv(\"SMTP_PORT\", \"587\"))\n",
    "    \n",
    "    # Schedule settings\n",
    "    SCHEDULE_INTERVAL_HOURS = int(os.getenv(\"SCHEDULE_INTERVAL_HOURS\", \"24\"))\n",
    "\n",
    "# --- Database Functions ---\n",
    "def initialize_db():\n",
    "    \"\"\"Initialize database connection pool and create tables if needed\"\"\"\n",
    "    global DB_POOL\n",
    "    \n",
    "    try:\n",
    "        # Create connection pool\n",
    "        DB_POOL = pool.SimpleConnectionPool(\n",
    "            1, 10, **Config.DB_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Create tables if they don't exist\n",
    "        with DB_POOL.getconn() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS weather_data (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        timestamp TIMESTAMPTZ,\n",
    "                        city TEXT,\n",
    "                        description TEXT,\n",
    "                        temperature REAL,\n",
    "                        feels_like REAL,\n",
    "                        humidity INTEGER,\n",
    "                        pressure INTEGER,\n",
    "                        wind_speed REAL,\n",
    "                        visibility INTEGER,\n",
    "                        sunrise TIMESTAMPTZ,\n",
    "                        sunset TIMESTAMPTZ,\n",
    "                        latitude REAL,\n",
    "                        longitude REAL\n",
    "                    )\n",
    "                \"\"\")\n",
    "                \n",
    "                # Create index on city and timestamp for faster queries\n",
    "                cur.execute(\"\"\"\n",
    "                    CREATE INDEX IF NOT EXISTS idx_weather_city_timestamp \n",
    "                    ON weather_data (city, timestamp)\n",
    "                \"\"\")\n",
    "                \n",
    "            conn.commit()\n",
    "            DB_POOL.putconn(conn)\n",
    "        \n",
    "        logger.info(\"Database initialized successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database initialization error: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Tasks ---\n",
    "@task(\n",
    "    retries=3,\n",
    "    retry_delay_seconds=30,\n",
    "    cache_key_fn=task_input_hash,\n",
    "    cache_expiration=timedelta(hours=1)\n",
    ")\n",
    "def extract_weather_data(city: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Fetch weather data from OpenWeather API\n",
    "    \n",
    "    Args:\n",
    "        city: Name of the city to get weather data for\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing weather data or None if retrieval failed\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    \n",
    "    if not Config.OPENWEATHER_API_KEY:\n",
    "        logger.error(\"OpenWeather API key not set\")\n",
    "        return None\n",
    "        \n",
    "    url = (\n",
    "        f\"https://api.openweathermap.org/data/2.5/weather\"\n",
    "        f\"?q={city}&appid={Config.OPENWEATHER_API_KEY}&units={Config.WEATHER_UNITS}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Fetching data for {city}\")\n",
    "        response = requests.get(url, timeout=Config.API_TIMEOUT)\n",
    "        \n",
    "        # Handle API errors\n",
    "        if response.status_code == 404:\n",
    "            logger.error(f\"City not found: {city}\")\n",
    "            return None\n",
    "        elif response.status_code == 429:\n",
    "            logger.error(\"API rate limit exceeded\")\n",
    "            # Wait longer before retry\n",
    "            raise requests.exceptions.RequestException(\"Rate limit exceeded\")\n",
    "        elif response.status_code != 200:\n",
    "            logger.error(f\"API error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "            \n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract data with validation\n",
    "        current_time = datetime.now(timezone.utc)\n",
    "        \n",
    "        # Sunrise and sunset times from UTC timestamps\n",
    "        sunrise = datetime.fromtimestamp(data[\"sys\"].get(\"sunrise\", 0), tz=timezone.utc)\n",
    "        sunset = datetime.fromtimestamp(data[\"sys\"].get(\"sunset\", 0), tz=timezone.utc)\n",
    "        \n",
    "        return {\n",
    "            \"timestamp\": current_time,\n",
    "            \"city\": data.get(\"name\", city),\n",
    "            \"description\": data[\"weather\"][0].get(\"description\", \"Unknown\"),\n",
    "            \"temperature\": data[\"main\"].get(\"temp\"),\n",
    "            \"feels_like\": data[\"main\"].get(\"feels_like\"),\n",
    "            \"humidity\": data[\"main\"].get(\"humidity\", 0),\n",
    "            \"pressure\": data[\"main\"].get(\"pressure\", 0),\n",
    "            \"wind_speed\": data[\"wind\"].get(\"speed\", 0),\n",
    "            \"visibility\": data.get(\"visibility\", 0),\n",
    "            \"sunrise\": sunrise,\n",
    "            \"sunset\": sunset,\n",
    "            \"latitude\": data[\"coord\"].get(\"lat\", 0),\n",
    "            \"longitude\": data[\"coord\"].get(\"lon\", 0)\n",
    "        }\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Request timed out for {city}\")\n",
    "        return None\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Connection error when fetching data for {city}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Request error for {city}: {e}\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Parsing error for {city}: Missing key {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error extracting data for {city}: {e}\")\n",
    "        return None\n",
    "\n",
    "@task(retries=2, retry_delay_seconds=15)\n",
    "def load_to_db(weather_data_list: List[Dict[str, Any]]) -> bool:\n",
    "    \"\"\"Load weather data into PostgreSQL\n",
    "    \n",
    "    Args:\n",
    "        weather_data_list: List of weather data dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating success or failure\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    \n",
    "    # Filter out None values (failed extractions)\n",
    "    valid_data = [data for data in weather_data_list if data is not None]\n",
    "    \n",
    "    if not valid_data:\n",
    "        logger.warning(\"No valid data to load\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        conn = DB_POOL.getconn()\n",
    "        with conn.cursor() as cur:\n",
    "            # Use batch insert for efficiency\n",
    "            query = \"\"\"\n",
    "                INSERT INTO weather_data (\n",
    "                    timestamp, city, description, temperature, feels_like,\n",
    "                    humidity, pressure, wind_speed, visibility, \n",
    "                    sunrise, sunset, latitude, longitude\n",
    "                ) VALUES (\n",
    "                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "                )\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\"\n",
    "            \n",
    "            data_tuples = [\n",
    "                (\n",
    "                    data[\"timestamp\"],\n",
    "                    data[\"city\"],\n",
    "                    data[\"description\"],\n",
    "                    data[\"temperature\"],\n",
    "                    data[\"feels_like\"],\n",
    "                    data[\"humidity\"],\n",
    "                    data[\"pressure\"],\n",
    "                    data[\"wind_speed\"],\n",
    "                    data[\"visibility\"],\n",
    "                    data[\"sunrise\"],\n",
    "                    data[\"sunset\"],\n",
    "                    data[\"latitude\"],\n",
    "                    data[\"longitude\"]\n",
    "                )\n",
    "                for data in valid_data\n",
    "            ]\n",
    "            \n",
    "            execute_batch(cur, query, data_tuples)\n",
    "            \n",
    "        conn.commit()\n",
    "        DB_POOL.putconn(conn)\n",
    "        logger.info(f\"Successfully loaded {len(valid_data)} records\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database error: {e}\")\n",
    "        # Try to return connection to pool if it was acquired\n",
    "        if 'conn' in locals():\n",
    "            DB_POOL.putconn(conn)\n",
    "        return False\n",
    "\n",
    "@task\n",
    "def generate_weather_report() -> Optional[str]:\n",
    "    \"\"\"Generate weekly weather report with statistics\n",
    "    \n",
    "    Returns:\n",
    "        String containing HTML report or None if generation failed\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    \n",
    "    # Skip if not Sunday and not in debug mode\n",
    "    today = datetime.now()\n",
    "    is_sunday = today.weekday() == 6\n",
    "    debug_mode = os.getenv(\"DEBUG_REPORT\", \"false\").lower() == \"true\"\n",
    "    \n",
    "    if not is_sunday and not debug_mode:\n",
    "        logger.info(\"Skipping report (not Sunday)\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        conn = DB_POOL.getconn()\n",
    "        with conn.cursor() as cur:\n",
    "            # Get data for the past week\n",
    "            one_week_ago = datetime.now(timezone.utc) - timedelta(days=7)\n",
    "            \n",
    "            # Query average temperatures by city for the past week\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    city, \n",
    "                    AVG(temperature) as avg_temp,\n",
    "                    MIN(temperature) as min_temp,\n",
    "                    MAX(temperature) as max_temp,\n",
    "                    AVG(humidity) as avg_humidity\n",
    "                FROM weather_data\n",
    "                WHERE timestamp > %s\n",
    "                GROUP BY city\n",
    "                ORDER BY city\n",
    "            \"\"\", (one_week_ago,))\n",
    "            \n",
    "            results = cur.fetchall()\n",
    "            \n",
    "        DB_POOL.putconn(conn)\n",
    "        \n",
    "        if not results:\n",
    "            logger.warning(\"No data for report\")\n",
    "            return None\n",
    "            \n",
    "        # Generate HTML report\n",
    "        html = f\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; }}\n",
    "                table {{ border-collapse: collapse; width: 100%; }}\n",
    "                th, td {{ padding: 8px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
    "                th {{ background-color: #f2f2f2; }}\n",
    "                .header {{ background-color: #4CAF50; color: white; padding: 15px; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"header\">\n",
    "                <h1>Weekly Weather Report</h1>\n",
    "                <p>Period: {one_week_ago.strftime('%Y-%m-%d')} to {today.strftime('%Y-%m-%d')}</p>\n",
    "            </div>\n",
    "            \n",
    "            <h2>Temperature Summary</h2>\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <th>City</th>\n",
    "                    <th>Avg Temp (°C)</th>\n",
    "                    <th>Min Temp (°C)</th>\n",
    "                    <th>Max Temp (°C)</th>\n",
    "                    <th>Avg Humidity (%)</th>\n",
    "                </tr>\n",
    "        \"\"\"\n",
    "        \n",
    "        for city, avg_temp, min_temp, max_temp, avg_humidity in results:\n",
    "            html += f\"\"\"\n",
    "                <tr>\n",
    "                    <td>{city}</td>\n",
    "                    <td>{avg_temp:.1f}</td>\n",
    "                    <td>{min_temp:.1f}</td>\n",
    "                    <td>{max_temp:.1f}</td>\n",
    "                    <td>{avg_humidity:.0f}</td>\n",
    "                </tr>\n",
    "            \"\"\"\n",
    "            \n",
    "        html += \"\"\"\n",
    "            </table>\n",
    "            <p>This report was automatically generated by the Weather ETL Pipeline.</p>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        return html\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Report generation error: {e}\")\n",
    "        # Try to return connection to pool if it was acquired\n",
    "        if 'conn' in locals():\n",
    "            DB_POOL.putconn(conn)\n",
    "        return None\n",
    "\n",
    "@task\n",
    "def send_email_report(report_html: Optional[str]) -> bool:\n",
    "    \"\"\"Send email with weather report\n",
    "    \n",
    "    Args:\n",
    "        report_html: HTML content of the report\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating success or failure\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    \n",
    "    if not report_html:\n",
    "        logger.info(\"No report to send\")\n",
    "        return False\n",
    "        \n",
    "    if not Config.EMAIL_ENABLED:\n",
    "        logger.info(\"Email sending disabled\")\n",
    "        return False\n",
    "        \n",
    "    if not all([Config.EMAIL_SENDER, Config.EMAIL_PASSWORD, Config.EMAIL_RECIPIENT]):\n",
    "        logger.error(\"Email configuration incomplete\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = Config.EMAIL_SENDER\n",
    "        msg['To'] = Config.EMAIL_RECIPIENT\n",
    "        msg['Subject'] = f\"Weekly Weather Report - {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "        \n",
    "        msg.attach(MIMEText(report_html, 'html'))\n",
    "        \n",
    "        with smtplib.SMTP(Config.SMTP_SERVER, Config.SMTP_PORT) as server:\n",
    "            server.starttls()\n",
    "            server.login(Config.EMAIL_SENDER, Config.EMAIL_PASSWORD)\n",
    "            server.send_message(msg)\n",
    "            \n",
    "        logger.info(\"Email report sent successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Email sending failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Main Flow ---\n",
    "@flow(name=\"Weather Data Pipeline\")\n",
    "def weather_pipeline():\n",
    "    \"\"\"Main flow for weather data collection and reporting\"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Starting weather pipeline\")\n",
    "    \n",
    "    # Initialize database\n",
    "    if not initialize_db():\n",
    "        logger.error(\"Database initialization failed, aborting pipeline\")\n",
    "        return\n",
    "    \n",
    "    # 1. Extract data for all cities in parallel\n",
    "    weather_data_list = []\n",
    "    for city in Config.CITIES:\n",
    "        result = extract_weather_data(city)\n",
    "        if result:\n",
    "            weather_data_list.append(result)\n",
    "    \n",
    "    # 2. Load data to database\n",
    "    load_success = load_to_db(weather_data_list)\n",
    "    \n",
    "    # 3. Generate and send weekly report\n",
    "    if load_success:\n",
    "        report_html = generate_weather_report()\n",
    "        if report_html:\n",
    "            send_email_report(report_html)\n",
    "    \n",
    "    logger.info(\"Weather pipeline completed\")\n",
    "\n",
    "# --- Run the flow ---\n",
    "if __name__ == \"__main__\":\n",
    "    weather_pipeline()\n",
    "\n",
    "# --- Create deployment (uncomment to deploy) ---\n",
    "if __name__ == \"__main__\":\n",
    "#     # For Prefect 2.x deployments, use the CLI or the following:\n",
    "#     # Import needed only if deploying\n",
    "    from prefect.deployments import Deployment\n",
    "    from prefect.orion.schemas.schedules import IntervalSchedule\n",
    "    \n",
    "    deployment = Deployment.build_from_flow(\n",
    "        flow=weather_pipeline,\n",
    "        name=\"scheduled-weather-pipeline\",\n",
    "        schedule=IntervalSchedule(interval=timedelta(hours=Config.SCHEDULE_INTERVAL_HOURS)),\n",
    "        work_queue_name=\"default\"\n",
    "    )\n",
    "    deployment.apply()\n",
    "\n",
    "#     # For newer Prefect versions (preferred method):\n",
    "#     # weather_pipeline.serve(\n",
    "#     #     name=\"scheduled-weather-pipeline\",\n",
    "#     #     interval=timedelta(hours=Config.SCHEDULE_INTERVAL_HOURS)\n",
    "#     # )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
